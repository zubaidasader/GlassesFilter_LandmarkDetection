## Landmark Detection - Sunglasses filter. 
Using OpenCV's Haar cascades to detect faces in a live video stream from a webcam and applies a pre-trained deep learning model to detect key facial keypoints. Based on the positions of these keypoints, it overlays a pair of glasses on the eyes of the detected faces in real-time. <br>
Data: https://www.kaggle.com/c/facial-keypoints-detection/overview <br>
### Data Preprocessing
We have to prepare and preprocesse data for a real-time face filter application using computer vision techniques. It takes the video input from a camera and detects faces using the Haar cascade classifier. It then crops and resizes the detected face region to 96x96 pixels and normalizes the pixel values between 0 and 1. The normalized face image is passed to a pre-trained deep learning model to predict facial keypoints, which are then used to position and scale a filter image. Finally, the filter is overlayed onto the original image using the alpha channel and displayed in real-time. The code also displays the predicted facial keypoints on a separate window for visualization purposes.
![image](https://user-images.githubusercontent.com/63263652/235899291-7497b3cc-1c17-4b34-804a-e677e8d5a801.png)

### Building Model
The model is built using a convolutional neural network (CNN) with multiple layers. The model is constructed using the Keras library and consists of several convolutional layers followed by a series of dense layers. The input to the model is an image of size 96x96 pixels, which is passed through the layers to generate an output of the same size. The output consists of 30 facial keypoints, including the coordinates for the center of the eyes, nose, mouth, and other facial landmarks. The model is trained on a dataset of facial images with associated keypoints, and the loss is calculated using mean squared error. The optimizer used is Adam, and the model is trained for several epochs.

### Apply Predictions on real time
The model predicts the facial keypoints using a pre-trained deep learning model, and overlay a filter (glasses) onto the face at the predicted keypoints. The keypoints are predicted using the pre-trained deep learning model, which takes in a grayscale image of the detected face and outputs the coordinates of 15 facial keypoints, such as the left and right eye, nose tip, and mouth corners. The predicted keypoints are then used to scale and position the filter onto the face at the appropriate locations. The filter is overlaid using the alpha channel to blend it seamlessly with the underlying image. The resulting output is then displayed in a window, along with a visualization of the predicted keypoints. The user can quit the application by pressing the 'q' key. <br>
![image](https://user-images.githubusercontent.com/63263652/235900913-c7a1d6fa-c882-40ef-bd57-152f84b8fe56.png)
